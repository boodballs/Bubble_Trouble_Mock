# Bubble Trouble Game - LLM Implementation Comparison

## Project Overview

This project explores the capabilities of different Large Language Models (LLMs) in generating a functional web-based game based on a detailed prompt. The goal was to implement a clone of the classic arcade game "Bubble Trouble" (also known as "Pang") using HTML, CSS, JavaScript, and the Three.js library.

The same comprehensive prompt detailing core gameplay mechanics, technical requirements, controls (desktop and mobile), and visual style was provided to various LLMs.

## Models Tested & Selected

Several models were tested, but this repository focuses on the implementations generated by:

1.  **Google Gemini 2.5 Pro**
2.  **Anthropic Claude 3.7 Sonnet**

These two models were selected specifically because they were the only ones tested that successfully generated a complete, runnable, and largely functional version of the game directly from the initial prompt **in a zero-shot manner**. This means they understood the requirements and produced the desired output without needing significant follow-up clarification, iteration, or debugging prompts.

## Implementations

You can find the resulting implementations in the following files:

* **Gemini 2.5 Pro:** [`gemini2_5_pro.html`](gemini2_5_pro.html)
* **Claude 3.7 Sonnet:** [`Claude_3_7_Sonnet.html`](Claude_3_7_Sonnet.html)

An index page is also provided to easily navigate between the two implementations:

* **Index:** [`index.html`](index.html) _(Assuming you rename the redirect page to index.html)_

## Purpose

This project serves as a comparative case study on the code generation abilities of current state-of-the-art LLMs when faced with a complex, multi-component task like game development based purely on a textual description. The success of Gemini 2.5 Pro and Claude 3.7 Sonnet in zero-shotting this prompt highlights their advanced understanding and generation capabilities.
